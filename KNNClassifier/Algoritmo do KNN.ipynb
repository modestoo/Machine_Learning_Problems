{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK - 1 - Testar com base de dados de Iris (ver se a predição deu certo) \n",
    "#### OK - 2 - Comparar com o algorítmo de KNN real\n",
    "#### 3 - Melhorar nomes das variáveis\n",
    "#### 4 - Comentar funções\n",
    "#### OK - 5 - Revisar funções em private OO\n",
    "#### OK - 6 - Criar função de score\n",
    "#### 7 - Revisar de há algum função proibida\n",
    "#### 8 - Criar novas funções de cálculo de distância (Euclidiana, Manhattan, Minkowski e distância de Hamming. As primeiras três funções são usadas para a função contínua e a quarta (Hamming) para variáveis categóricas)\n",
    "#### 9 - Criar Matriz de Confusão\n",
    "#### 10 - Finalizar nootebook (instânciando o meu modelo e comparando com o modelo original KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observações quanto ao exercício\n",
    "\n",
    "# Funções atômicas para facilitar os testes unitários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # Para calcular a raiz quadrada\n",
    "import csv # Para abrir o arquivo CSV e carregar na memória\n",
    "import random # Para gerar a aleatoriedade para separar as bases de teste e train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManupulaArquivo:\n",
    "    '''\n",
    "    Esta classe é responsável por fornecer métodos que permitam a manipulação de arquivos para trabalhar com\n",
    "    bases de dados, especificamente, para trabalhar com algorítmos de machine learning (ML).\n",
    "    \n",
    "    Lista de Atributos:\n",
    "        N/A\n",
    "    \n",
    "    Lista de Métodos Públicos:\n",
    "        load_dataset = carrega um dataset na memoria.\n",
    "        train_test_split = separa um dataset em duas listas (variáveis repostas e variáveis preditoras) de treino\n",
    "                           e duas listas (variáveis repostas e variáveis preditoras) de teste, utilizando o método\n",
    "                           de validação cruzada holdout.\n",
    "    \n",
    "    Lista de Métodos Privados:\n",
    "        __shuffle_dataset = randomiza um dataset.\n",
    "        __separate_dataset = separa o dataset em duas listas de treino e teste.\n",
    "        __remove_predictor_element = remove o elemento preditor das lista de treino e teste.\n",
    "    '''\n",
    "    \n",
    "    def load_dataset(self, path_file):\n",
    "        '''\n",
    "        Método público que carrega um csv na memória do nootbook.\n",
    "        Retorna a base de dados em formato de lista.\n",
    "        \n",
    "        Args:\n",
    "            path_file(str): O caminho do arquivo CSV. Caso esteja na mesma pasta do nootbook, basta inserir o\n",
    "                            nome do arquivo. Não é necessário adicionar a extensão do arquivo (.csv).\n",
    "        \n",
    "        Returns:\n",
    "            dataset(list): Uma lista com os dados do CSV de entrada carregado na memória.\n",
    "        '''\n",
    "        with open(path_file) as csv_file:\n",
    "            dataset = list(csv.reader(csv_file))\n",
    "        return dataset\n",
    "\n",
    "    def __shuffle_dataset(self, dataset, test_ratio):\n",
    "        '''\n",
    "        Método privado que embaralha o dataset, isto é, randomiza a base de dados.\n",
    "        Retorna a base de dados randomizada e a proporção da base para teste do modelo.\n",
    "        \n",
    "        Args:\n",
    "            dataset(list): A base de dados contendo os dados em formato de lista carregados na memória.\n",
    "            \n",
    "            test_ratio(float): Tamanho (proporção) da base de teste em valor percentual.\n",
    "            \n",
    "        Returns:\n",
    "            shuffled_dataset(list): Uma lista com os dados do dataset randomizados (embaralhados).\n",
    "            \n",
    "            test_size(int): Tamanho (inteiro) da base de dados em valor absoluto (Ex: 200 linhas do dataset randomizado). \n",
    "        '''\n",
    "        shuffled_dataset = random.sample(dataset, len(dataset))\n",
    "        test_size = int(len(dataset) * test_ratio)        \n",
    "        return shuffled_dataset, test_size \n",
    "    \n",
    "    def __separate_dataset(self, shuffled_dataset, test_size):\n",
    "        '''\n",
    "        Método privado que separa um dataset, preferencialmente randomizado (embaralhados), em duas lista: uma para treino\n",
    "        e outra para teste.\n",
    "        Retorna as duas listas de treino e teste.\n",
    "        \n",
    "        Args:\n",
    "            shuffled_dataset(list): Uma lista com os dados do dataset, preferencialmente randomizados (embaralhados).\n",
    "            \n",
    "            test_size(float): Tamanho (proporção) da base de teste.\n",
    "            \n",
    "        Returns:\n",
    "            train_data(list): Uma lista com os dados para treinamento do modelo, de acordo com a proporção\n",
    "            fornecida de teste.\n",
    "            \n",
    "            test_data(list): Uma lista com os dados para teste do modelo, de acordo com a proporção\n",
    "            fornecida de teste.\n",
    "        '''\n",
    "        test_data = shuffled_dataset[:test_size]\n",
    "        train_data = shuffled_dataset[test_size:]\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def __remove_predictor_element(self, train_data, test_data):\n",
    "        '''\n",
    "        Método privado que remove o elemento preditor, considerando como sendo o último elemento, do dataset.\n",
    "        Retorna quatro lista contendo os elementos seletores (varíaveis respostas) e os valores preditores\n",
    "        de treino e teste.\n",
    "        \n",
    "        Args:\n",
    "            train_data(list): Uma lista com os dados para treinamento do modelo, de acordo com a proporção\n",
    "            fornecida de teste.\n",
    "            \n",
    "            test_data(list): Uma lista com os dados para teste do modelo, de acordo com a proporção\n",
    "            fornecida de teste.\n",
    "        \n",
    "        Returns:\n",
    "            train_X(list): Uma lista contendo os elementos seletores (varíaveis respostas) da lista de treino.\n",
    "            \n",
    "            train_y(list): Uma lista contendo os elementos seletores (varíaveis respostas) da lista de teste.\n",
    "            \n",
    "            test_X(list): Uma lista contendo os elementos preditores (varíaveis preditoras) da lista de treino.\n",
    "            \n",
    "            test_y(list): Uma lista contendo os elementos preditores (varíaveis preditoras) da lista de teste.\n",
    "        '''\n",
    "        last_element = -1\n",
    "        train_X = [sample[:last_element] for sample in train_data]\n",
    "        train_y = [sample[last_element] for sample in train_data]\n",
    "        test_X = [sample[:last_element] for sample in test_data]\n",
    "        test_y = [sample[last_element] for sample in test_data]\n",
    "        return train_X, train_y, test_X, test_y\n",
    "    \n",
    "    def train_test_split(self, dataset, test_ratio=0.3):\n",
    "        '''\n",
    "        Método público que separa uma base de dados em quatro listas para treino e teste de um modelo de machine learning\n",
    "        utilizando o método de validação cruzada holdout.\n",
    "        Retorna quatro lista contendo os elementos seletores (varíaveis respostas) e os valores preditores\n",
    "        de treino e teste.\n",
    "        \n",
    "        Args:\n",
    "            dataset(list): A base de dados contendo os dados em formato de lista carregados na memória.\n",
    "            \n",
    "            test_ratio(float): Tamanho (proporção) da base de teste em valor percentual. Por default o valor\n",
    "            desta variável é 0.3 (30%).\n",
    "        \n",
    "        Returns:\n",
    "            train_X(list): Uma lista contendo os elementos seletores (varíaveis respostas) da lista de treino.\n",
    "            \n",
    "            train_y(list): Uma lista contendo os elementos seletores (varíaveis respostas) da lista de teste.\n",
    "            \n",
    "            test_X(list): Uma lista contendo os elementos preditores (varíaveis preditoras) da lista de treino.\n",
    "            \n",
    "            test_y(list): Uma lista contendo os elementos preditores (varíaveis preditoras) da lista de teste.\n",
    "        \n",
    "        '''\n",
    "        shuffled_dataset, test_size = self.__shuffle_dataset(dataset, test_ratio)\n",
    "        train_data, test_data = self.__separate_dataset(shuffled_dataset, test_size)\n",
    "        train_X, train_y, test_X, test_y = self.__remove_predictor_element(train_data, test_data)\n",
    "        return train_X, train_y, test_X, test_y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe KNN\n",
    "class KNeighborsClassifier:\n",
    "    '''\n",
    "        \n",
    "    '''\n",
    "\n",
    "    def __init__(self, k=3, method='euclidean'):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.k = k\n",
    "        self.method = method\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def calculate_distance(self, points_p, points_q):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        sum_points = 0\n",
    "        \n",
    "        # De acordo com o Wikipedia, a distância euclidiana é dado pela Raiz Quadrada do Somatório((Pi - Qi)²)\n",
    "        if self.method == 'euclidean': \n",
    "            dimension_points = len(points_p)\n",
    "            #print('dimension_points: ', dimension_points)\n",
    "            #print(points_p,\"//\", points_q, \"\\n\\n\")\n",
    "            for i in range(dimension_points):\n",
    "                #print(points_p[i], points_q[i], float(points_p[i]), float(points_q[i]))\n",
    "                sum_points += (float(points_p[i]) - float(points_q[i]))**2\n",
    "                #print(sum_points)\n",
    "        \n",
    "        # De acordo com ....\n",
    "        elif self.method == 'manhattan':\n",
    "            sum_points = 9\n",
    "            \n",
    "        return math.sqrt(sum_points)\n",
    "    \n",
    "    def compara_distancias(self, instancia_test):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        result_compara = []\n",
    "        dimension_x_train = len(self.x_train)\n",
    "        for i in range(dimension_x_train):\n",
    "            result_compara.append(self.calculate_distance(self.x_train[i], instancia_test))\n",
    "        return result_compara\n",
    "    \n",
    "    def encontra_menor_distancia(self, result_compara):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        ranged = range(len(result_compara))\n",
    "        return sorted(ranged, key=lambda i: result_compara[i])[:self.k]\n",
    "    \n",
    "    def encontra_label(self, k_menores_distancias):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        labels_k = []\n",
    "        for i in k_menores_distancias:\n",
    "            labels_k.append(self.y_train[i])\n",
    "        return labels_k\n",
    "    \n",
    "    def predict_label(self, labels_k):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        return max(labels_k, key=labels_k.count)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        result_predict = []\n",
    "        #print('x_test: ', x_test)\n",
    "        for instance_x_test in x_test:\n",
    "            #print('instância: ', instance_x_test)\n",
    "            result_distance = self.compara_distancias(instance_x_test)\n",
    "            result_menor_distance = self.encontra_menor_distancia(result_distance)\n",
    "            result_label = self.encontra_label(result_menor_distance)\n",
    "            result_predict_label = self.predict_label(result_label)\n",
    "            result_predict.append(result_predict_label)                \n",
    "        return result_predict\n",
    "    \n",
    "    def prediction_report(self, predictions, test_y):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        for i, prediction in enumerate(predictions):\n",
    "            print('Real:', test_y[i], '\\t Predito:', prediction)\n",
    "\n",
    "    def accuracy_report(self, predictions, test_y):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        acertos = 0\n",
    "        for i, j in zip(predictions, test_y):\n",
    "            if i == j:\n",
    "                acertos += 1\n",
    "                \n",
    "        #accuracy = sum(i == j for i, j in zip(predictions, test_y)) / len(test_y) * 100.0\n",
    "        print('Quantidade de Treinos:', len(self.x_train))\n",
    "        print('Quantidade de Testes:', len(test_y))\n",
    "        print('Quantidade de Acertos:', acertos)\n",
    "        print('Quantidade de Erros:', (len(test_y)-acertos))\n",
    "        print('Acurácia do Modelo: %.2f%%' % (acertos*100/len(test_y)))\n",
    "        \n",
    "        # Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 120 120 30 30\n",
      "[['5.2', '2.7', '3.9', '1.4'], ['5.1', '3.5', '1.4', '0.2'], ['5.6', '2.8', '4.9', '2.0']] \n",
      " ['Iris-versicolor', 'Iris-setosa', 'Iris-virginica'] \n",
      " [['6.9', '3.2', '5.7', '2.3'], ['5.5', '3.5', '1.3', '0.2'], ['6.3', '2.3', '4.4', '1.3']] \n",
      " ['Iris-virginica', 'Iris-setosa', 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "ma = ManupulaArquivo()\n",
    "dataset = ma.load_dataset(\"iris.data\")\n",
    "train_X, train_y, test_X, test_y = ma.train_test_split(dataset, test_ratio=0.2)\n",
    "print('\\n',len(train_X), len(train_y), len(test_X), len(test_y))\n",
    "print(train_X[:3], '\\n', train_y[:3], '\\n', test_X[:3], '\\n', test_y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier()\n",
    "knn2.fit(train_X,train_y)\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = knn2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Treinos: 120\n",
      "Quantidade de Testes: 30\n",
      "Quantidade de Acertos: 28\n",
      "Quantidade de Erros: 2\n",
      "Acurácia do Modelo: 93.33%\n"
     ]
    }
   ],
   "source": [
    "knn2.accuracy_report(result, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: Iris-virginica \t Predito: Iris-virginica\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-virginica \t Predito: Iris-virginica\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-virginica\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-virginica \t Predito: Iris-virginica\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-virginica \t Predito: Iris-virginica\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-virginica \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n",
      "Real: Iris-versicolor \t Predito: Iris-versicolor\n",
      "Real: Iris-setosa \t Predito: Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "knn2.prediction_report(result, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_iris()\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(dataset['data'], dataset['target'], random_state=0)\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciando o modelo KNN\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Treinando os dados\n",
    "knn.fit(train_X,train_y)\n",
    "\n",
    "# Para medir a accuracy, utiliza-se o método score passando a base de teste e os valores preditos\n",
    "knn.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataseta(path_file):\n",
    "    with open(path_file) as csv_file:\n",
    "        dataset = list(csv.reader(csv_file))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csvfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-5b4590f9b6f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataseta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iris.data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-2a0681617c4b>\u001b[0m in \u001b[0;36mload_dataseta\u001b[0;34m(path_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataseta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csvfile' is not defined"
     ]
    }
   ],
   "source": [
    "t = load_dataseta(\"iris.data\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Função que carrega um csv na memória do nootbook.\n",
      "        Returna a base de dados em formato de lista\n",
      "        \n",
      "        Args:\n",
      "            path_file(str): O caminho do arquivo CSV. Caso esteja na mesma pasta do nootbook, basta inserir o\n",
      "                            nome do arquivo. Não é necessário adicionar a extensão do arquivo (.csv).\n",
      "        \n",
      "        Returns:\n",
      "            dataset(list): Uma lista com os dados do CSV de entrada carregado na memória.\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(ma.load_dataset.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
